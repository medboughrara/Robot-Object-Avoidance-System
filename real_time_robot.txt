import cv2
import numpy as np
import serial
import time
import os
import argparse

class RobotController:
    def __init__(self, serial_port='/dev/ttyACM0', baud_rate=9600):
        """Initialize the robot controller with serial connection to Arduino"""
        try:
            self.serial_conn = serial.Serial(serial_port, baud_rate, timeout=1)
            time.sleep(2)  # Wait for Arduino to reset
            print(f"Connected to Arduino on {serial_port}")
        except Exception as e:
            print(f"Error connecting to Arduino: {e}")
            print("If you're on Windows, try using 'COM3' (or another COM port)")
            print("If you're on Linux, try using '/dev/ttyACM0' or '/dev/ttyUSB0'")
            exit(1)

    def send_command(self, command):
        """Send a command to the Arduino"""
        try:
            self.serial_conn.write(command.encode())
            time.sleep(0.05)  # Reduced delay for faster response
        except Exception as e:
            print(f"Error sending command: {e}")

    def move_forward(self):
        self.send_command("F\n")

    def move_backward(self):
        self.send_command("B\n")

    def turn_left(self):
        self.send_command("L\n")

    def turn_right(self):
        self.send_command("R\n")

    def stop(self):
        self.send_command("S\n")

class ObjectDetector:
    def __init__(self, confidence_threshold=0.5):
        """Initialize the YOLO-tiny object detector"""
        # Define the path to YOLO files
        yolo_path = os.path.join(os.path.dirname(__file__), 'yolo_files')
        cfg_path = os.path.join(yolo_path, 'yolov3-tiny.cfg')
        weights_path = os.path.join(yolo_path, 'yolov3-tiny.weights')
        names_path = os.path.join(yolo_path, 'coco.names')

        # Check if files exist
        for file_path in [cfg_path, weights_path, names_path]:
            if not os.path.exists(file_path):
                print(f"Error: Required file not found: {file_path}")
                exit(1)

        # Load YOLO-tiny model
        print("Loading YOLO-tiny model...")
        self.net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)
        
        # Optimize for performance
        self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_DEFAULT)
        self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
        
        # Load classes
        with open(names_path, 'r') as f:
            self.classes = [line.strip() for line in f]

        self.confidence_threshold = confidence_threshold
        self.input_size = (416, 416)  # Reduced for better performance
        print("Model loaded successfully!")

    def detect_objects(self, frame):
        """Perform optimized object detection on a frame"""
        # Resize frame for faster processing
        height, width = frame.shape[:2]
        
        # Create blob and set as input
        blob = cv2.dnn.blobFromImage(frame, 1/255.0, self.input_size, 
                                   swapRB=True, crop=False)
        self.net.setInput(blob)
        
        # Get output layer names
        layer_names = self.net.getLayerNames()
        output_layers = [layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]
        
        # Forward pass with timing
        start_time = time.time()
        outputs = self.net.forward(output_layers)
        inference_time = time.time() - start_time
        
        # Process detections
        boxes = []
        confidences = []
        class_ids = []
        detected_objects = []
        
        # Process each detection
        for output in outputs:
            for detection in output:
                scores = detection[5:]
                class_id = np.argmax(scores)
                confidence = scores[class_id]
                
                if confidence > self.confidence_threshold:
                    center_x = int(detection[0] * width)
                    center_y = int(detection[1] * height)
                    w = int(detection[2] * width)
                    h = int(detection[3] * height)
                    
                    x = int(center_x - w/2)
                    y = int(center_y - h/2)
                    
                    boxes.append([x, y, w, h])
                    confidences.append(float(confidence))
                    class_ids.append(class_id)
                    
                    detected_objects.append({
                        'label': self.classes[class_id],
                        'confidence': confidence,
                        'center': (center_x, center_y),
                        'box': (x, y, w, h)
                    })
        
        # Apply non-maximum suppression
        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 
                                 self.confidence_threshold, 0.4)
        
        # Draw boxes and display FPS
        fps = 1.0 / inference_time
        cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        filtered_detections = []
        for i in range(len(boxes)):
            if i in indexes:
                x, y, w, h = boxes[i]
                label = str(self.classes[class_ids[i]])
                confidence = confidences[i]
                
                # Draw rectangle and label
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                cv2.putText(frame, f'{label} {confidence:.2f}', 
                           (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 
                           0.5, (0, 255, 0), 2)
                
                filtered_detections.append(detected_objects[i])
        
        return frame, filtered_detections, fps

def main():
    parser = argparse.ArgumentParser(description='Real-time Robot Object Avoidance')
    parser.add_argument('--camera', type=int, default=0,
                        help='Camera index (default: 0)')
    parser.add_argument('--serial-port', type=str,
                        default='/dev/ttyACM0' if os.name != 'nt' else 'COM3',
                        help='Serial port for Arduino')
    parser.add_argument('--confidence', type=float, default=0.5,
                        help='Confidence threshold (0-1)')
    args = parser.parse_args()

    # Initialize robot controller and object detector
    robot = RobotController(serial_port=args.serial_port)
    detector = ObjectDetector(confidence_threshold=args.confidence)

    # Initialize camera with reduced resolution for better performance
    cap = cv2.VideoCapture(args.camera)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    if not cap.isOpened():
        print(f"Error: Could not open camera {args.camera}")
        exit(1)

    print("Starting real-time object avoidance system...")
    print("Press 'q' to quit")

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("Error: Can't receive frame from camera")
                break

            # Detect objects
            frame, detections, fps = detector.detect_objects(frame)
            
            # Process detections and control robot
            if detections:
                # Get the closest/largest object
                closest_detection = max(detections, 
                                     key=lambda x: x['box'][2] * x['box'][3])
                
                # Calculate relative position
                frame_center_x = frame.shape[1] / 2
                object_center_x = closest_detection['center'][0]
                object_width = closest_detection['box'][2]
                
                # Simple proportional control
                position_error = object_center_x - frame_center_x
                
                # Decision making
                if object_width > frame.shape[1] * 0.4:  # Object too close
                    print(f"Object too close - Moving backward (FPS: {fps:.1f})")
                    robot.move_backward()
                elif abs(position_error) > 50:  # Object significantly off-center
                    if position_error < 0:
                        print(f"Object on left - Moving right (FPS: {fps:.1f})")
                        robot.turn_right()
                    else:
                        print(f"Object on left - Moving left (FPS: {fps:.1f})")
                        robot.turn_left()
                else:
                    print(f"Path clear - Moving forward (FPS: {fps:.1f})")
                    robot.move_forward()
            else:
                print(f"No objects detected - Moving forward (FPS: {fps:.1f})")
                robot.move_forward()

            # Display the frame
            cv2.imshow('Robot Vision (YOLOv3-tiny)', frame)

            # Break loop on 'q' press
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    except KeyboardInterrupt:
        print("\nProgram interrupted by user")

    finally:
        # Clean up
        robot.stop()
        robot.serial_conn.close()
        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()